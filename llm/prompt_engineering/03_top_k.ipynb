{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Top-K sampling\n",
    "sampling selects the top K most likely tokens from the model’s predicted distribution. The higher top-K, the more creative and varied the model’s output; the lower top-K, the more restive and factual the model’s output. A top-K of 1 is equivalent to greedy decoding.\n",
    "\n",
    "## Example"
   ],
   "id": "cfea97fb05ccf0ab"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T13:02:52.595236Z",
     "start_time": "2025-04-23T13:02:49.089394Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from ollama import generate, Options, GenerateResponse\n",
    "from typing import Iterator\n",
    "\n",
    "stream: Iterator[GenerateResponse] = generate(\n",
    "    model=\"gemma3:12b\",\n",
    "    prompt=\"what is the capital of Germany?\",\n",
    "    options=Options(top_k=40),\n",
    "    stream=True\n",
    ")\n",
    "for chunk in stream:\n",
    "    print(chunk.response, end=\"\", flush=True)"
   ],
   "id": "41185b20c62f3e6d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of Germany is **Berlin**.\n",
      "\n",
      "\n",
      "\n",
      "It's also the largest city in Germany!"
     ]
    }
   ],
   "execution_count": 3
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
